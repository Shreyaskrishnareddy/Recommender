# 📓 Jupyter Notebook: Recommender_Systems.ipynb

**Notebook Overview:**
- Total Cells: 34
- Code Cells: 25
- Markdown Cells: 9

**Kernel:** Python 3 (ipykernel)

**Language:** python 3.10.13

## 📋 Notebook Content:

### 📝 Markdown Cell 1

# Lesson 3 - Recommender Systems

---

### 📝 Markdown Cell 2

### Import the Needed Packages

---

### 🔹 Code Cell 3 [Execution: 1]

```python
import warnings
warnings.filterwarnings('ignore')
```

---

### 🔹 Code Cell 4 [Execution: 3]

```python
!pip install langchain
```

**Output:**
```
Collecting langchain
  Downloading langchain-0.2.6-py3-none-any.whl (975 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m975.5/975.5 kB[0m [31m12.1 MB/s[0m eta [36m0:00:00[0m
[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)
Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)
Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)
Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)
Collecting langchain-core<0.3.0,>=0.2.10 (from langchain)
  Downloading langchain_core-0.2.10-py3-none-any.whl (332 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m332.8/332.8 kB[0m [31m35.8 MB/s[0m eta [36m0:00:00[0m
[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)
  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)
Collecting langsmith<0.2.0,>=0.1.17 (from langchain)
  Downloading langsmith-0.1.82-py3-none-any.whl (127 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m127.4/127.4 kB[0m [31m17.7 MB/s[0m eta [36m0:00:00[0m
[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)
Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.4)
Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)
Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.1)
Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)
Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)
Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)
Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)
Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)
Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.10->langchain)
  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)
Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (24.1)
Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)
  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m145.0/145.0 kB[0m [31m15.8 MB/s[0m eta [36m0:00:00[0m
[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)
Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)
Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)
Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)
Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)
Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)
Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain)
  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)
Installing collected packages: orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain
Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.6 langchain-core-0.2.10 langchain-text-splitters-0.2.2 langsmith-0.1.82 orjson-3.10.5
```

---

### 🔹 Code Cell 5 [Execution: 5]

```python
!pip install openai
```

**Output:**
```
Collecting openai
  Downloading openai-1.35.7-py3-none-any.whl (327 kB)
[?25l     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/327.5 kB[0m [31m?[0m eta [36m-:--:--[0m[2K     [91m━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━[0m [32m143.4/327.5 kB[0m [31m4.2 MB/s[0m eta [36m0:00:01[0m[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m327.5/327.5 kB[0m [31m6.0 MB/s[0m eta [36m0:00:00[0m
[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)
Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)
Collecting httpx<1,>=0.23.0 (from openai)
  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m75.6/75.6 kB[0m [31m10.7 MB/s[0m eta [36m0:00:00[0m
[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.4)
Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)
Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)
Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)
Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)
Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)
Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)
Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)
  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m77.9/77.9 kB[0m [31m10.1 MB/s[0m eta [36m0:00:00[0m
[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)
  Downloading h11-0.14.0-py3-none-any.whl (58 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m58.3/58.3 kB[0m [31m8.2 MB/s[0m eta [36m0:00:00[0m
[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)
Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)
Installing collected packages: h11, httpcore, httpx, openai
Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.7
```

---

### 🔹 Code Cell 6 [Execution: 7]

```python
!pip install pinecone-client
```

**Output:**
```
Collecting pinecone-client
  Downloading pinecone_client-4.1.1-py3-none-any.whl (216 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m216.2/216.2 kB[0m [31m4.0 MB/s[0m eta [36m0:00:00[0m
[?25hRequirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.6.2)
Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client)
  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)
Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.4)
Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.12.2)
Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.0.7)
Installing collected packages: pinecone-plugin-interface, pinecone-client
Successfully installed pinecone-client-4.1.1 pinecone-plugin-interface-0.0.7
```

---

### 🔹 Code Cell 9 [Execution: 9]

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter
from openai import OpenAI
from pinecone import Pinecone, ServerlessSpec
from tqdm.auto import tqdm, trange
#from DLAIUtils import Utils

import pandas as pd
import time
import os
```

---

### 🔹 Code Cell 10 [Execution: 30]

```python
# Create or update DLAIUtils.py file
with open('DLAIUtils.py', 'w') as file:
    file.write('''
class Utils:
    def __init__(self):
        # Initialize your class here, if needed
        pass

    def get_pinecone_api_key(self):
        # Replace with your actual method to get the API key
        return "c78d18ee-4be1-429b-8260-5b8ef2d8e18a"

    def get_openai_api_key(self):
        # Replace with your actual method to get the API key
        return "sk-proj-YOUR_OPENAI_PROJECT_KEY_HERE"

    def create_dlai_index_name(self, base_name):
        # Replace with your actual method to create a DLAI index name
        return f"{base_name}-index"
    ''')
```

---

### 🔹 Code Cell 11 [Execution: 33]

```python
# Import the Utils class from the DLAIUtils.py file
from importlib import reload  # Add this import
import DLAIUtils
reload(DLAIUtils)  # Reload the module to reflect changes
from DLAIUtils import Utils

# Create an instance of Utils
utils = Utils()

# Get the API keys
PINECONE_API_KEY = utils.get_pinecone_api_key()
OPENAI_API_KEY = utils.get_openai_api_key()

# Use the create_dlai_index_name method
INDEX_NAME = utils.create_dlai_index_name('dl-ai')

# Print the INDEX_NAME to verify (optional)
print("Index Name:", INDEX_NAME)

# Initialize OpenAI and Pinecone clients
openai_client = OpenAI(api_key=OPENAI_API_KEY)
pinecone = Pinecone(api_key=PINECONE_API_KEY)

# Check if the index exists and delete it if it does
if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:
    pinecone.delete_index(INDEX_NAME)

# Create a new index
pinecone.create_index(name=INDEX_NAME, dimension=1536, metric='cosine',
                      spec=ServerlessSpec(cloud='aws', region='us-east-1'))

# Access the newly created index
index = pinecone.Index(INDEX_NAME)
```

**Output:**
```
Index Name: dl-ai-index
```

---

### 📝 Markdown Cell 13

### Load the Dataset

**Note:** To access the dataset outside of this course, just copy the following two lines of code and run it (remember to uncomment them first before executing):

!wget -q --show-progress -O all-the-news-3.zip "https://www.dropbox.com/scl/fi/wruzj2bwyg743d0jzd7ku/all-the-news-3.zip?rlkey=rgwtwpeznbdadpv3f01sznwxa&dl=1"

!unzip all-the-news-3.zip

---

### 🔹 Code Cell 14 [Execution: 34]

```python
!wget -q --show-progress -O all-the-news-3.zip "https://www.dropbox.com/scl/fi/wruzj2bwyg743d0jzd7ku/all-the-news-3.zip?rlkey=rgwtwpeznbdadpv3f01sznwxa&dl=1"

!unzip all-the-news-3.zip
```

**Output:**
```
all-the-news-3.zip  100%[===================>] 166.04M  22.3MB/s    in 7.8s    
Archive:  all-the-news-3.zip
replace all-the-news-3.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:
```

---

### 🔹 Code Cell 15 [Execution: 35]

```python
with open('/content/all-the-news-3.csv', 'r') as f:
    header = f.readline()
    print(header)
```

**Output:**
```
date,year,month,day,author,title,article,url,section,publication
```

---

### 🔹 Code Cell 16 [Execution: 36]

```python
df = pd.read_csv('/content/all-the-news-3.csv', nrows=99)
df.head()
```

**Output:**
```
date  year  month  day       author  \
0  2016-12-09 18:31:00  2016   12.0    9  Lee Drutman   
1  2016-10-07 21:26:46  2016   10.0    7  Scott Davis   
2  2018-01-26 00:00:00  2018    1.0   26          NaN   
3  2019-06-27 00:00:00  2019    6.0   27          NaN   
4  2016-01-27 00:00:00  2016    1.0   27          NaN   

                                               title  \
0  We should take concerns about the health of li...   
1  Colts GM Ryan Grigson says Andrew Luck's contr...   
2       Trump denies report he ordered Mueller fired   
3  France's Sarkozy reveals his 'Passions' but in...   
4  Paris Hilton: Woman In Black For Uncle Monty's...   

                                             article  \
0  This post is part of Polyarchy, an independent...   
1   The Indianapolis Colts made Andrew Luck the h...   
2  DAVOS, Switzerland (Reuters) - U.S. President ...   
3  PARIS (Reuters) - Former French president Nico...   
4  Paris Hilton arrived at LAX Wednesday dressed ...   

                                                 url     section  \
0  https://www.vox.com/polyarchy/2016/12/9/138983...         NaN   
1  https://www.businessinsider.com/colts-gm-ryan-...         NaN   
2  https://www.reuters.com/article/us-davos-meeti...       Davos   
3  https://www.reuters.com/article/france-politic...  World News   
4  https://www.tmz.com/2016/01/27/paris-hilton-mo...         NaN   

        publication  
0               Vox  
1  Business Insider  
2           Reuters  
3           Reuters  
4               TMZ
```

---

### 📝 Markdown Cell 17

### Setup Pinecone

---

### 🔹 Code Cell 18 [Execution: 38]

```python
openai_client = OpenAI(api_key=OPENAI_API_KEY)
# util = Utils()  # This variable is not used, so we can remove it
INDEX_NAME = utils.create_dlai_index_name('dl-ai') # Use utils
pinecone = Pinecone(api_key=PINECONE_API_KEY)

if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:
  pinecone.delete_index(INDEX_NAME)

pinecone.create_index(name=INDEX_NAME, dimension=1536, metric='cosine',
  spec=ServerlessSpec(cloud='aws', region='us-east-1'))

index = pinecone.Index(INDEX_NAME)
```

---

### 📝 Markdown Cell 19

### 1.  Create Embeddings of the News Titles

---

### 🔹 Code Cell 20 [Execution: 39]

```python
def get_embeddings(articles, model="text-embedding-ada-002"):
   return openai_client.embeddings.create(input = articles, model=model)
```

---

### 🔹 Code Cell 21 [Execution: 41]

```python
CHUNK_SIZE=400
TOTAL_ROWS=10000
progress_bar = tqdm(total=TOTAL_ROWS)
chunks = pd.read_csv('/content/all-the-news-3.csv', chunksize=CHUNK_SIZE,
                     nrows=TOTAL_ROWS)
chunk_num = 0
for chunk in chunks:
    titles = chunk['title'].tolist()
    embeddings = get_embeddings(titles)
    prepped = [{'id':str(chunk_num*CHUNK_SIZE+i), 'values':embeddings.data[i].embedding,
                'metadata':{'title':titles[i]},} for i in range(0,len(titles))]
    chunk_num = chunk_num + 1
    if len(prepped) >= 200:
      index.upsert(prepped)
      prepped = []
    progress_bar.update(len(chunk))
```

**Output:**
```
0%|          | 0/10000 [00:00<?, ?it/s]
```

---

### 🔹 Code Cell 22 [Execution: 42]

```python
index.describe_index_stats()
```

**Output:**
```
{'dimension': 1536,
 'index_fullness': 0.0,
 'namespaces': {'': {'vector_count': 10000}},
 'total_vector_count': 10000}
```

---

### 📝 Markdown Cell 23

### Build the Recommender System

---

### 🔹 Code Cell 24 [Execution: 43]

```python
def get_recommendations(pinecone_index, search_term, top_k=10):
  embed = get_embeddings([search_term]).data[0].embedding
  res = pinecone_index.query(vector=embed, top_k=top_k, include_metadata=True)
  return res
```

---

### 🔹 Code Cell 25 [Execution: 44]

```python
reco = get_recommendations(index, 'obama')
for r in reco.matches:
    print(f'{r.score} : {r.metadata["title"]}')
```

**Output:**
```
0.849984109 : Barack Obama just stepped off the sidelines to defend Obamacare
0.848674893 : President Obama has a new plan to fight the opioid epidemic
0.848271608 : “Our democracy is at stake”: Obama delivers his first post-presidency campaign speech
0.848052 : Obama: if you were fine with big government until it served black people, rethink your biases
0.845821619 : President Obama: Michelle & I Are Gonna Be Renters
0.844207942 : Obama meets with national security team on Syria, Islamic State
0.843172133 : Vox Sentences: Obama got a warmer welcome in Hiroshima than the Japanese prime minister
0.84271574 : Watch President Obama dance the tango in Argentina
0.840892255 : Obama and Supreme Court Tag Team on Juvenile Justice Reform
0.840887129 : Barack Obama in talks to create shows for Netflix: New York Times
```

---

### 📝 Markdown Cell 26

### 2.  Create Embeddings of All News Content

---

### 🔹 Code Cell 27 [Execution: 46]

```python
if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:
  pinecone.delete_index(name=INDEX_NAME)

pinecone.create_index(name=INDEX_NAME, dimension=1536, metric='cosine',
  spec=ServerlessSpec(cloud='aws', region='us-east-1'))
articles_index = pinecone.Index(INDEX_NAME)
```

---

### 🔹 Code Cell 28 [Execution: 47]

```python
def embed(embeddings, title, prepped, embed_num):
  for embedding in embeddings.data:
    prepped.append({'id':str(embed_num), 'values':embedding.embedding, 'metadata':{'title':title}})
    embed_num += 1
    if len(prepped) >= 100:
        articles_index.upsert(prepped)
        prepped.clear()
  return embed_num
```

---

### 📝 Markdown Cell 29

<p style="background-color:#fff1d7; padding:15px; "> <b>(Note: <code>news_data_rows_num = 100</code>):</b> In this lab, we've initially set <code>news_data_rows_num</code> to 100 for speedier results, allowing you to observe the outcomes faster. Once you've done an initial run, consider increasing this value to 200, 400, 700, and 1000. You'll likely notice better and more relevant results.</p>

---

### 🔹 Code Cell 30 [Execution: 49]

```python
news_data_rows_num = 100

embed_num = 0 #keep track of embedding number for 'id'
text_splitter = RecursiveCharacterTextSplitter(chunk_size=400,
    chunk_overlap=20) # how to chunk each article
prepped = []
df = pd.read_csv('/content/all-the-news-3.csv', nrows=news_data_rows_num)
articles_list = df['article'].tolist()
titles_list = df['title'].tolist()

for i in range(0, len(articles_list)):
    print(".",end="")
    art = articles_list[i]
    title = titles_list[i]
    if art is not None and isinstance(art, str):
      texts = text_splitter.split_text(art)
      embeddings = get_embeddings(texts)
      embed_num = embed(embeddings, title, prepped, embed_num)
```

**Output:**
```
....................................................................................................
```

---

### 🔹 Code Cell 31 [Execution: 50]

```python
articles_index.describe_index_stats()
```

**Output:**
```
{'dimension': 1536,
 'index_fullness': 0.0,
 'namespaces': {'': {'vector_count': 1000}},
 'total_vector_count': 1000}
```

---

### 📝 Markdown Cell 32

### Build the Recommender System

---

### 🔹 Code Cell 33 [Execution: 51]

```python
reco = get_recommendations(articles_index, 'obama', top_k=100)
seen = {}
for r in reco.matches:
    title = r.metadata['title']
    if title not in seen:
        print(f'{r.score} : {title}')
        seen[title] = '.'
```

**Output:**
```
0.821158946 : Why Obama is vetting Nevada's Republican governor for the Supreme Court
0.818882763 : U.S. lawmakers ask for disclosure of number of Americans under surveillance
0.812377512 : NYPD Honcho Insulted by 'Hamilton' Star Lin-Manuel Miranda Celebrating Obama's Controversial Prisoner Release
0.806862772 : Why Jews Are Getting Themselves Arrested at ICE Centers Around the Country
0.806241512 : Trump keeping options open as Republican feud rages
0.801216245 : Michael Bloomberg Is Seriously Considering a Presidential Run
0.800062716 : The most revealing Republican ad of the election is an attack ad against Tim Kaine
0.798267 : Exclusive: Trump considering fracking mogul Harold Hamm as energy secretary - sources
0.797588 : Trump tells anti-abortion marchers he will support them
0.79740876 : The government official in charge of ethics just harshly condemned Trump’s plan
0.793474555 : Exclusive: China shuns U.S. request for talks on airline website dispute over Taiwan
0.79241544 : “Elizabeth Warren called me!” is turning into a Twitter meme
0.789711893 : Nancy Pelosi says a Clinton landslide could put the House in play. The math backs her up.
0.78738308 : Republicans totally outsmarted the mainstream media on Obamacare repeal
0.784224868 : Peter Thiel vs. the FDA
0.782173753 : France's Sarkozy reveals his 'Passions' but insists no come-back on cards
0.782062232 : It's 2018, and these white supremacists are running for office
0.781876624 : China is dismissing unfavorable media reports as fake because that's what Trump does
0.78141278 : We should take concerns about the health of liberal democracy seriously
0.780468106 : How the Clinton campaign is making #ThatMexicanThing a thing, explained
0.779447556 : How one woman used fashion to reclaim her Muslim American identity
0.778261781 : Mass protests have erupted in Poland 
0.778227329 : IEA concerned about Middle East tensions, stands ready to act
0.776038229 : How love and marriage are changing, according to 63,000 New York Times wedding announcements
```

---
